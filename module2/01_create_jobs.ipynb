{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-intro",
   "metadata": {},
   "source": [
    "# Module 2: Creating CML Jobs Programmatically\n",
    "\n",
    "## Overview\n",
    "\n",
    "In Module 1, you built a complete ML pipeline using Python scripts executed manually. In Module 2, we'll automate this pipeline using **CML Jobs** - scheduled or triggered tasks that run your scripts at scale.\n",
    "\n",
    "This notebook teaches you how to **create jobs programmatically** using the CML API. Instead of clicking through the UI, you'll write code to define, configure, and manage jobs. This approach enables:\n",
    "\n",
    "- **Automation**: Create multiple jobs with consistent configurations\n",
    "- **Reproducibility**: Version control your job definitions\n",
    "- **Integration**: Orchestrate complex workflows programmatically\n",
    "- **Scalability**: Deploy jobs across projects and environments\n",
    "- **GitOps**: Store job definitions in version control\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this notebook, you'll understand:\n",
    "\n",
    "1. ✅ How to authenticate with CML API\n",
    "2. ✅ How to query available ML runtimes\n",
    "3. ✅ How to retrieve project metadata\n",
    "4. ✅ How to define a job using `cmlapi.CreateJobRequest`\n",
    "5. ✅ How to create jobs programmatically\n",
    "6. ✅ How to configure job dependencies (chaining jobs)\n",
    "\n",
    "**Note**: We will **create** jobs but not **run** them in this notebook. Running jobs will be covered separately.\n",
    "\n",
    "## Module 2 Job Pipeline Structure\n",
    "\n",
    "This notebook creates **4 jobs** that work together in a monitoring pipeline:\n",
    "\n",
    "```\n",
    "Job 02: Prepare Artificial Data\n",
    "        ↓\n",
    "        └─→ Calls cmlapi.create_job_run() for Job 03.1\n",
    "        \n",
    "Job 03.1: Get Predictions\n",
    "        ↓\n",
    "        └─→ Calls cmlapi.create_job_run() for Job 03.2\n",
    "        \n",
    "Job 03.2: Load Ground Truth\n",
    "        ↓\n",
    "        └─→ Calls cmlapi.create_job_run() for Job 03.3\n",
    "        \n",
    "Job 03.3: Check Model\n",
    "        ↓\n",
    "        └─→ Decides if pipeline continues or stops\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section-1",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Authentication\n",
    "\n",
    "### Step 1.1: Import Required Libraries\n",
    "\n",
    "We need key libraries:\n",
    "- **`cmlapi`**: Official CML Python API client for programmatic access\n",
    "- **`os`**: To access environment variables set by CML\n",
    "- **`json`**: For parsing runtime filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cmlapi\n",
    "import json\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section-1-2",
   "metadata": {},
   "source": [
    "### Step 1.2: Create CML API Client\n",
    "\n",
    "The CML API client authenticates your requests using credentials automatically provided by CML:\n",
    "\n",
    "- **`CDSW_API_URL`**: The CML API endpoint for your workspace\n",
    "- **`CDSW_APIV2_KEY`**: Your authentication token\n",
    "\n",
    "We remove `/api/v1` from the URL since the client handles API versioning internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-auth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CML API client created successfully\n",
      "  API URL: https://ml-dbfc64d1-783.go01-dem.ylcu-atmi.cloudera.site/api/v1\n"
     ]
    }
   ],
   "source": [
    "# Create the CML API client\n",
    "# The client uses environment variables automatically set by CML for authentication\n",
    "client = cmlapi.default_client(\n",
    "    url=os.getenv(\"CDSW_API_URL\").replace(\"/api/v1\", \"\"),\n",
    "    cml_api_key=os.getenv(\"CDSW_APIV2_KEY\")\n",
    ")\n",
    "\n",
    "print(\"✓ CML API client created successfully\")\n",
    "print(f\"  API URL: {os.getenv('CDSW_API_URL')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section-1-3",
   "metadata": {},
   "source": [
    "### Step 1.3: Retrieve Available ML Runtimes\n",
    "\n",
    "Jobs execute in **ML Runtimes** - pre-configured Docker containers with specific Python versions, libraries, and GPU support. We need to query available runtimes that match our requirements.\n",
    "\n",
    "In this example, we filter for:\n",
    "- **kernel**: \"Python 3.10\" - Python version\n",
    "- **edition**: \"Standard\" - Standard edition\n",
    "- **editor**: \"PBJ Workbench\" - JupyterLab interface for development\n",
    "\n",
    "**Important Notes:**\n",
    "- Runtimes from **2024.05 onwards** include ML packages (pandas, numpy, scikit-learn, etc.)\n",
    "- We select the **NEWEST runtime** to ensure all dependencies are included\n",
    "- Older runtimes (2023.x) lack pandas and will cause `ModuleNotFoundError` in jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-runtimes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Found 10 available runtime(s)\n",
      "\n",
      "Runtime 1:\n",
      "  Version: 2023.05.1-b4\n",
      "  Kernel: Python 3.10\n",
      "  Edition: Standard\n",
      "  Image: container.repository.cloudera.com/cloudera/cdsw/ml-runtime-pbj-workbench-python3.10-standard:2023.05.1-b4\n",
      "\n",
      "Runtime 2:\n",
      "  Version: 2023.05.1-b4\n",
      "  Kernel: Python 3.10\n",
      "  Edition: Standard\n",
      "  Image: docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-pbj-workbench-python3.10-standard:2023.05.1-b4\n",
      "\n",
      "Runtime 3:\n",
      "  Version: 2023.05.2-b7\n",
      "  Kernel: Python 3.10\n",
      "  Edition: Standard\n",
      "  Image: docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-pbj-workbench-python3.10-standard:2023.05.2-b7\n",
      "\n",
      "Runtime 4:\n",
      "  Version: 2023.08.1-b6\n",
      "  Kernel: Python 3.10\n",
      "  Edition: Standard\n",
      "  Image: docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-pbj-workbench-python3.10-standard:2023.08.1-b6\n",
      "\n",
      "Runtime 5:\n",
      "  Version: 2023.08.2-b8\n",
      "  Kernel: Python 3.10\n",
      "  Edition: Standard\n",
      "  Image: docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-pbj-workbench-python3.10-standard:2023.08.2-b8\n",
      "\n",
      "Runtime 6:\n",
      "  Version: 2023.12.1-b8\n",
      "  Kernel: Python 3.10\n",
      "  Edition: Standard\n",
      "  Image: docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-pbj-workbench-python3.10-standard:2023.12.1-b8\n",
      "\n",
      "Runtime 7:\n",
      "  Version: 2024.02.1-b4\n",
      "  Kernel: Python 3.10\n",
      "  Edition: Standard\n",
      "  Image: docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-pbj-workbench-python3.10-standard:2024.02.1-b4\n",
      "\n",
      "Runtime 8:\n",
      "  Version: 2024.05.1-b8\n",
      "  Kernel: Python 3.10\n",
      "  Edition: Standard\n",
      "  Image: docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-pbj-workbench-python3.10-standard:2024.05.1-b8\n",
      "\n",
      "Runtime 9:\n",
      "  Version: 2024.05.2-b14\n",
      "  Kernel: Python 3.10\n",
      "  Edition: Standard\n",
      "  Image: docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-pbj-workbench-python3.10-standard:2024.05.2-b14\n",
      "\n",
      "Runtime 10:\n",
      "  Version: 2024.10.1-b12\n",
      "  Kernel: Python 3.10\n",
      "  Edition: Standard\n",
      "  Image: docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-pbj-workbench-python3.10-standard:2024.10.1-b12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query available runtimes matching our criteria\n",
    "# The search_filter is a JSON string with our runtime requirements\n",
    "available_runtimes = client.list_runtimes(\n",
    "    search_filter=json.dumps({\n",
    "        \"kernel\": \"Python 3.10\",\n",
    "        \"edition\": \"Standard\",\n",
    "        \"editor\": \"PBJ Workbench\"\n",
    "    })\n",
    ")\n",
    "print(f\"✓ Found {len(available_runtimes.runtimes)} available runtime(s)\\n\")\n",
    "\n",
    "# Display all available runtimes\n",
    "for i, runtime in enumerate(available_runtimes.runtimes, 1):\n",
    "    print(f\"Runtime {i}:\")\n",
    "    print(f\"  Version: {runtime.full_version}\")\n",
    "    print(f\"  Kernel: {runtime.kernel}\")\n",
    "    print(f\"  Edition: {runtime.edition}\")\n",
    "    print(f\"  Image: {runtime.image_identifier}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section-1-4",
   "metadata": {},
   "source": [
    "### Step 1.4: Select and Store the Latest Runtime\n",
    "\n",
    "We'll use the **first (most recent) runtime** from our filtered list. This runtime identifier will be passed to job creation calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-runtime-select",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Selected Runtime (NEWEST):\n",
      "  Version: 2024.10.1-b12\n",
      "  Image: docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-pbj-workbench-python3.10-standard:2024.10.1-b12\n",
      "  Note: Only 2024+ runtimes include ML packages (pandas, numpy, scikit-learn)\n",
      "  ✓ Runtime includes pandas and ML libraries\n"
     ]
    }
   ],
   "source": [
    "# Select the latest runtime (sort by version, newest first)\n",
    "sorted_runtimes = sorted(available_runtimes.runtimes, key=lambda r: r.full_version, reverse=True)\n",
    "JOB_IMAGE_ML_RUNTIME = sorted_runtimes[0].image_identifier\n",
    "\n",
    "print(f\"✓ Selected Runtime (NEWEST):\")\n",
    "print(f\"  Version: {sorted_runtimes[0].full_version}\")\n",
    "print(f\"  Image: {JOB_IMAGE_ML_RUNTIME}\")\n",
    "print(f\"  Note: Only 2024+ runtimes include ML packages (pandas, numpy, scikit-learn)\")\n",
    "\n",
    "# Verify this is a recent runtime with pandas\n",
    "if \"2024\" not in sorted_runtimes[0].full_version:\n",
    "    print(f\"\\n⚠️  WARNING: Selected runtime {sorted_runtimes[0].full_version} may not have pandas!\")\n",
    "    print(f\"  Recommended: Use 2024.05+ or 2024.10+\")\n",
    "else:\n",
    "    print(f\"  ✓ Runtime includes pandas and ML libraries\")\n",
    "\n",
    "# Store in environment variable for use in job definitions\n",
    "os.environ['JOB_IMAGE_ML_RUNTIME'] = JOB_IMAGE_ML_RUNTIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section-1-5",
   "metadata": {},
   "source": [
    "### Step 1.5: Retrieve Project Metadata\n",
    "\n",
    "Jobs are created within a specific CML project. We retrieve the current project's metadata to get its ID and other information needed for job creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-project",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Project Retrieved:\n",
      "  Project ID: crfy-i66p-le3j-cdss\n",
      "  Project Name: CAI Baseline MLOPS\n",
      "  Description: \n"
     ]
    }
   ],
   "source": [
    "# Get metadata for the current CML project\n",
    "# CDSW_PROJECT_ID is automatically set when you run code in a CML project\n",
    "project = client.get_project(\n",
    "    project_id=os.getenv(\"CDSW_PROJECT_ID\")\n",
    ")\n",
    "\n",
    "print(f\"✓ Project Retrieved:\")\n",
    "print(f\"  Project ID: {project.id}\")\n",
    "print(f\"  Project Name: {project.name}\")\n",
    "print(f\"  Description: {project.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section-2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Job Creation - The Monitoring Pipeline\n",
    "\n",
    "### Understanding Job Definitions\n",
    "\n",
    "A CML job is defined using `cmlapi.CreateJobRequest` with these key parameters:\n",
    "\n",
    "| Parameter | Purpose | Example |\n",
    "|-----------|---------|----------|\n",
    "| `project_id` | Which project to create the job in | `project.id` |\n",
    "| `name` | Human-readable job name | `\"Get Predictions\"` |\n",
    "| `script` | Path to Python script to run | `\"03.1_get_predictions.py\"` |\n",
    "| `cpu` | CPU cores to allocate | `2` |\n",
    "| `memory` | RAM in GB to allocate | `4` |\n",
    "| `runtime_identifier` | ML Runtime image to use | `JOB_IMAGE_ML_RUNTIME` |\n",
    "| `environment` | Environment variables for the job | `{\"PERIOD\": \"0\"}` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section-2-1",
   "metadata": {},
   "source": [
    "### Step 2.1: Create Job 02 - Prepare Artificial Data\n",
    "\n",
    "This is the entry point to the monitoring pipeline. It prepares synthetic data for the workflow.\n",
    "The notebook will then trigger Job 03.1 (Get Predictions) after completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-job02-define",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 02 Definition - Prepare Artificial Data:\n",
      "  Script: module2/02_prepare_artificial_data.py\n",
      "  CPU: 1 cores\n",
      "  Memory: 2 GB\n"
     ]
    }
   ],
   "source": [
    "# Define Job 02: Prepare Artificial Data\n",
    "# This is the entry point that triggers the entire pipeline\n",
    "\n",
    "job_body_prepare_data = cmlapi.CreateJobRequest(\n",
    "    project_id=project.id,\n",
    "    name=\"Job 02: Prepare Artificial Data\",\n",
    "    script=\"module2/02_prepare_artificial_data.py\",\n",
    "    cpu=1,\n",
    "    memory=2,\n",
    "    runtime_identifier=os.getenv('JOB_IMAGE_ML_RUNTIME'),\n",
    "\n",
    ")\n",
    "\n",
    "print(\"Job 02 Definition - Prepare Artificial Data:\")\n",
    "print(f\"  Script: {job_body_prepare_data.script}\")\n",
    "print(f\"  CPU: {job_body_prepare_data.cpu} cores\")\n",
    "print(f\"  Memory: {job_body_prepare_data.memory} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-job02-create",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Job 02 Created Successfully!\n",
      "  Job ID: psgr-5s9o-fwnu-kgpu\n",
      "  Job Name: Job 02: Prepare Artificial Data\n",
      "  Script: module2/02_prepare_artificial_data.py\n"
     ]
    }
   ],
   "source": [
    "# Create Job 02 in CML\n",
    "# This registers the job with CML but does NOT run it\n",
    "job_02_prepare_data = client.create_job(\n",
    "    body=job_body_prepare_data,\n",
    "    project_id=str(project.id)\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Job 02 Created Successfully!\")\n",
    "print(f\"  Job ID: {job_02_prepare_data.id}\")\n",
    "print(f\"  Job Name: {job_02_prepare_data.name}\")\n",
    "print(f\"  Script: {job_02_prepare_data.script}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9f3b8b8-0fce-41ba-9425-66e947001533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cmlapi.models.job.Job"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(job_02_prepare_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section-2-2",
   "metadata": {},
   "source": [
    "### Step 2.2: Create Job 03.1 - Get Predictions\n",
    "\n",
    "This job processes predictions for the current period in batches.\n",
    "It is triggered by Job 02 via `cmlapi.create_job_run()` in the job script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-job031-define",
   "metadata": {},
   "outputs": [],
   "source": "# Define Job 03.1: Get Predictions\n# This job loads period data, processes it in batches, and tracks predictions\n\njob_body_get_predictions = cmlapi.CreateJobRequest(\n    project_id=project.id,\n    name=\"Get Predictions\",\n    script=\"module2/03.1_get_predictions.py\",\n    cpu=2,\n    memory=4,\n    runtime_identifier=os.getenv('JOB_IMAGE_ML_RUNTIME'),\n\n)\n\nprint(\"Job 03.1 Definition - Get Predictions:\")\nprint(f\"  Script: {job_body_get_predictions.script}\")\nprint(f\"  CPU: {job_body_get_predictions.cpu} cores\")\nprint(f\"  Memory: {job_body_get_predictions.memory} GB\")"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-job031-create",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Job 03.1 Created Successfully!\n",
      "  Job ID: 3wtt-x1lt-iitx-oori\n",
      "  Job Name: Job 03.1: Get Predictions\n",
      "  Script: module2/03.1_get_predictions.py\n"
     ]
    }
   ],
   "source": [
    "# Create Job 03.1 in CML\n",
    "job_031_get_predictions = client.create_job(\n",
    "    body=job_body_get_predictions,\n",
    "    project_id=str(project.id)\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Job 03.1 Created Successfully!\")\n",
    "print(f\"  Job ID: {job_031_get_predictions.id}\")\n",
    "print(f\"  Job Name: {job_031_get_predictions.name}\")\n",
    "print(f\"  Script: {job_031_get_predictions.script}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section-2-3",
   "metadata": {},
   "source": [
    "### Step 2.3: Create Job 03.2 - Load Ground Truth\n",
    "\n",
    "This job loads ground truth labels for the current period.\n",
    "It is triggered by Job 03.1 after predictions are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-job032-define",
   "metadata": {},
   "outputs": [],
   "source": "# Define Job 03.2: Load Ground Truth\n# This job loads labels for the current period and validates predictions\n\njob_body_load_ground_truth = cmlapi.CreateJobRequest(\n    project_id=project.id,\n    name=\"Load Ground Truth\",\n    script=\"module2/03.2_load_ground_truth.py\",\n    cpu=1,\n    memory=2,\n    runtime_identifier=os.getenv('JOB_IMAGE_ML_RUNTIME')\n)\n\nprint(\"Job 03.2 Definition - Load Ground Truth:\")\nprint(f\"  Script: {job_body_load_ground_truth.script}\")\nprint(f\"  CPU: {job_body_load_ground_truth.cpu} cores\")\nprint(f\"  Memory: {job_body_load_ground_truth.memory} GB\")"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-job032-create",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Job 03.2 Created Successfully!\n",
      "  Job ID: a64l-b07m-ouic-e1sh\n",
      "  Job Name: Job 03.2: Load Ground Truth\n",
      "  Script: module2/03.2_load_ground_truth.py\n"
     ]
    }
   ],
   "source": [
    "# Create Job 03.2 in CML\n",
    "job_032_load_ground_truth = client.create_job(\n",
    "    body=job_body_load_ground_truth,\n",
    "    project_id=str(project.id)\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Job 03.2 Created Successfully!\")\n",
    "print(f\"  Job ID: {job_032_load_ground_truth.id}\")\n",
    "print(f\"  Job Name: {job_032_load_ground_truth.name}\")\n",
    "print(f\"  Script: {job_032_load_ground_truth.script}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section-2-4",
   "metadata": {},
   "source": [
    "### Step 2.4: Create Job 03.3 - Check Model\n",
    "\n",
    "This job validates model accuracy for the current period and orchestrates the monitoring pipeline.\n",
    "It is triggered by Job 03.2 after ground truth labels are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-job033-define",
   "metadata": {},
   "outputs": [],
   "source": "# Define Job 03.3: Check Model Performance\n# This job calculates accuracy metrics and detects degradation\n\njob_body_check_model = cmlapi.CreateJobRequest(\n    project_id=project.id,\n    name=\"Check Model\",\n    script=\"module2/03.3_check_model.py\",\n    cpu=1,\n    memory=2,\n    runtime_identifier=os.getenv('JOB_IMAGE_ML_RUNTIME'),\n\n)\n\nprint(\"Job 03.3 Definition - Check Model:\")\nprint(f\"  Script: {job_body_check_model.script}\")\nprint(f\"  CPU: {job_body_check_model.cpu} cores\")\nprint(f\"  Memory: {job_body_check_model.memory} GB\")"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-job033-create",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Job 03.3 Created Successfully!\n",
      "  Job ID: 88vy-os3t-njrx-9hw0\n",
      "  Job Name: Job 03.3: Check Model\n",
      "  Script: module2/03.3_check_model.py\n"
     ]
    }
   ],
   "source": [
    "# Create Job 03.3 in CML\n",
    "job_033_check_model = client.create_job(\n",
    "    body=job_body_check_model,\n",
    "    project_id=str(project.id)\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Job 03.3 Created Successfully!\")\n",
    "print(f\"  Job ID: {job_033_check_model.id}\")\n",
    "print(f\"  Job Name: {job_033_check_model.name}\")\n",
    "print(f\"  Script: {job_033_check_model.script}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Job Orchestration and Summary\n",
    "\n",
    "### Understanding the Job Pipeline\n",
    "\n",
    "The four jobs we created work together in an automated monitoring pipeline:\n",
    "\n",
    "**Pipeline Flow:**\n",
    "\n",
    "```\n",
    "Job 02: Prepare Artificial Data\n",
    "   (Entry point - prepares synthetic data)\n",
    "        ↓\n",
    "   job_02_prepare_data.py calls:\n",
    "   client.create_job_run(..., job_id=job_031_get_predictions.id)\n",
    "        ↓\n",
    "Job 03.1: Get Predictions\n",
    "   (Processes predictions for current period in batches)\n",
    "        ↓\n",
    "   job_031_get_predictions.py calls:\n",
    "   client.create_job_run(..., job_id=job_032_load_ground_truth.id)\n",
    "        ↓\n",
    "Job 03.2: Load Ground Truth\n",
    "   (Loads and processes ground truth labels)\n",
    "        ↓\n",
    "   job_032_load_ground_truth.py calls:\n",
    "   client.create_job_run(..., job_id=job_033_check_model.id)\n",
    "        ↓\n",
    "Job 03.3: Check Model\n",
    "   (Validates accuracy and detects degradation)\n",
    "        ↓\n",
    "   Decides: Continue pipeline or stop\n",
    "```\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "1. Job 02 runs and prepares the data\n",
    "2. At the end, Job 02's script calls `client.create_job_run()` to trigger Job 03.1\n",
    "3. Job 03.1 gets predictions for the period\n",
    "4. At the end, Job 03.1's script calls `client.create_job_run()` to trigger Job 03.2\n",
    "5. Job 03.2 loads ground truth labels\n",
    "6. At the end, Job 03.2's script calls `client.create_job_run()` to trigger Job 03.3\n",
    "7. Job 03.3 validates model accuracy and decides next steps\n",
    "\n",
    "This approach allows:\n",
    "- ✅ Sequential execution (each job waits for the previous to complete)\n",
    "- ✅ Data passing between jobs (via files or environment variables)\n",
    "- ✅ Dynamic decision logic (Job 03.3 can decide whether to continue the pipeline)\n",
    "- ✅ Resilience (if a job fails, the pipeline stops safely)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section-3-1",
   "metadata": {},
   "source": [
    "### Step 3.1: Display Complete Job Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-summary",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*80)\nprint(\"ALL 4 JOBS CREATED SUCCESSFULLY\")\nprint(\"=\"*80)\n\njobs = [\n    (\"Job 02\", job_02_prepare_data, \"Entry point - prepares synthetic data\"),\n    (\"Job 03.1\", job_031_get_predictions, \"Processes predictions in batches\"),\n    (\"Job 03.2\", job_032_load_ground_truth, \"Loads ground truth labels\"),\n    (\"Job 03.3\", job_033_check_model, \"Validates model accuracy\")\n]\n\nfor label, job, description in jobs:\n    print(f\"\\n{label}: {job.name}\")\n    print(f\"  ID: {job.id}\")\n    print(f\"  Script: {job.script}\")\n    print(f\"  CPU: {job.cpu} cores\")\n    print(f\"  Memory: {job.memory} GB\")\n    print(f\"  Purpose: {description}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"NEXT STEPS\")\nprint(\"=\"*80)\nprint(\"\"\"\n✓ All 4 jobs have been created programmatically\n✓ Jobs are now registered in CML but have NOT been run\n\nTo run the jobs:\n\n1. Option A - Run via CML UI:\n   - Go to your project's Jobs tab\n   - Click on \"Prepare Artificial Data\"\n   - Select \"Run Now\"\n   - The job will automatically trigger the downstream jobs (Get Predictions → Load Ground Truth → Check Model)\n\n2. Option B - Run via API (next notebook):\n   - Use client.create_job_run() to trigger \"Prepare Artificial Data\"\n   - Downstream jobs will trigger automatically\n   - Poll for completion status\n\nJob Orchestration Pattern (Best Practice for Labs):\n  • Jobs discover downstream jobs by NAME within the project\n  • Each job searches for and triggers the next job by name\n  • This is more readable for students and easier to understand\n  • Pattern: job_response = client.list_jobs(search_filter={\"name\": \"Job Name\"})\n  • Extract job_id from result and call client.create_job_run()\n\nKey Learning Points:\n  • Jobs are created once, run many times\n  • Each run can have different environment variables\n  • Job names enable orchestration (search by name, extract ID, trigger)\n  • cmlapi enables GitOps workflows for job management\n  • This 4-job pipeline automates the complete monitoring workflow\n\"\"\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-key-concepts",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Concepts Review\n",
    "\n",
    "### Authentication\n",
    "```python\n",
    "client = cmlapi.default_client(\n",
    "    url=os.getenv(\"CDSW_API_URL\").replace(\"/api/v1\", \"\"),\n",
    "    cml_api_key=os.getenv(\"CDSW_APIV2_KEY\")\n",
    ")\n",
    "```\n",
    "CML automatically provides API credentials in environment variables.\n",
    "\n",
    "### Selecting Runtimes\n",
    "```python\n",
    "available_runtimes = client.list_runtimes(\n",
    "    search_filter=json.dumps({\"kernel\": \"Python 3.10\"})\n",
    ")\n",
    "```\n",
    "Query available ML Runtimes with specific configurations (Python version, GPU, editor).\n",
    "\n",
    "### Creating Jobs\n",
    "```python\n",
    "job_body = cmlapi.CreateJobRequest(\n",
    "    project_id=project.id,\n",
    "    name=\"Job Name\",\n",
    "    script=\"script.py\",\n",
    "    cpu=2,\n",
    "    memory=4,\n",
    "    runtime_identifier=runtime_id,\n",
    "    environment={\"VAR\": \"value\"}\n",
    ")\n",
    "\n",
    "job = client.create_job(body=job_body, project_id=project.id)\n",
    "```\n",
    "Define job configuration and create it in CML (does NOT run automatically).\n",
    "\n",
    "### Job Orchestration - Triggering Downstream Jobs\n",
    "```python\n",
    "# Inside a job script (e.g., 02_prepare_artificial_data.py):\n",
    "client = cmlapi.default_client(...)\n",
    "project = client.get_project(...)\n",
    "\n",
    "# Trigger the next job in the pipeline\n",
    "client.create_job_run(\n",
    "    cmlapi.CreateJobRunRequest(),\n",
    "    project_id=project.id,\n",
    "    job_id=next_job_id  # This triggers Job 03.1\n",
    ")\n",
    "```\n",
    "Jobs can trigger dependent jobs programmatically, enabling workflow automation without manual intervention.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary: The 4-Job Pipeline\n",
    "\n",
    "You've just created a production-grade monitoring pipeline using CML Jobs:\n",
    "\n",
    "| Job | Purpose | Triggered By |\n",
    "|-----|---------|---------------|\n",
    "| 02 | Prepare synthetic data | Manual (UI or API) |\n",
    "| 03.1 | Get predictions from model | Job 02 |\n",
    "| 03.2 | Load ground truth labels | Job 03.1 |\n",
    "| 03.3 | Check model accuracy & degradation | Job 03.2 |\n",
    "\n",
    "This is how real-world ML monitoring systems work - **automated, reproducible, and scalable**.\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "In the next notebook, you'll:\n",
    "1. Learn how to **run jobs** using `client.create_job_run()`\n",
    "2. Monitor job execution and track progress\n",
    "3. Handle errors and job failures\n",
    "4. Implement the complete automated monitoring pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}